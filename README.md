# **Deel Limericks**
I once trained an AI to rhyme, It took GPT-J a long time.,</br>
Since the Colab was slow, I upgraded to Pro,</br> Each limerick cost me a dime.

By Robert. A Gonsalves</br>

![image](https://raw.githubusercontent.com/robgon-art/DeepLimericks/main/deep_limericks_med.jpg)

You can see my article on Medium

The source code and generated Haikus are released under the [CC BY-SA license](https://creativecommons.org/licenses/by-sa/4.0/).</br>
![CC BYC-SA](https://licensebuttons.net/l/by-sa/3.0/88x31.png)

## Google Colabs
* [Deep Limericks Trainer](https://colab.research.google.com/github/robgon-art/DeepLimericks/blob/main/Deep_Limericks_Train_GPT_J_6B.ipynb)
* [Deep Limericks Generator](https://colab.research.google.com/github/robgon-art/DeepLimericks/blob/main/Deep_Limericks_Interactive_Generator.ipynb)

## Acknowledgements
- GPT-J, B. Wang and A. Komatsuzaki, Mesh-Transformer-JAX: Model-Parallel Implementation of Transformer Language Model with JAX (2021)
- Limericks Dataset, A. Abdibayev, A. Riddell, Y. Igarashi, and D. Rockmore, Dataset of limericks for computational poetics (2021)
- KeyBert, M. Grootendorst, KeyBERT: Minimal keyword extraction with BERT (2020)
- Phonemizer, M. Bernard, Phonemizer: Text to Phones Transcription for Multiple Languages in Python (2016)
- The Pile, L. Gao et al., The Pile: An 800GB Dataset of Diverse Text for Language Modeling (2020)

## Citation
To cite this repository:

```bibtex
@software{DeepLimericks,
  author  = {Gonsalves, Robert A.},
  title   = {Deep Limericks},
  url     = {https://github.com/robgon-art/Limericks},
  year    = 2022,
  month   = October
}
```

